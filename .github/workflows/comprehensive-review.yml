name: Comprehensive Review Test

on:
  push:
  workflow_dispatch:

jobs:
  setup:
    runs-on: ubuntu-latest
    timeout-minutes: 3
    outputs:
      opencode-cache-key: ${{ steps.cache-key.outputs.key }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Generate cache key
        id: cache-key
        run: |
          echo "key=opencode-$(runner.os)-$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Cache OpenCode installation
        id: cache-opencode
        uses: actions/cache@v4
        with:
          path: |
            ~/.opencode
            ~/.config/opencode
          key: ${{ steps.cache-key.outputs.key }}

      - name: Install OpenCode
        if: steps.cache-opencode.outputs.cache-hit != 'true'
        run: |
          echo "Installing OpenCode..."
          curl -fsSL https://opencode.ai/install | bash
          echo "OpenCode installation completed"

      - name: Configure OpenCode
        if: steps.cache-opencode.outputs.cache-hit != 'true'
        run: |
          mkdir -p "$HOME/.config/opencode"
          cp .github/opencode/config.json "$HOME/.config/opencode/config.json"

      - name: Test OpenCode Installation
        run: |
          export PATH="$HOME/.opencode/bin:$PATH"
          opencode --version
          echo "âœ… OpenCode installation successful and cached!"

  # ==========================================
  # ðŸ”’ SECURITY & COMPLIANCE STREAM
  # ==========================================
  
  security-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: setup
    with:
      review-name: security
      prompt-file: .github/prompts/security.prompt.md
      timeout-minutes: 10
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  compliance-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, security-review]
    with:
      review-name: compliance
      prompt-file: .github/prompts/compliance.prompt.md
      timeout-minutes: 18
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  safety-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, compliance-review]
    with:
      review-name: safety
      prompt-file: .github/prompts/safety.prompt.md
      timeout-minutes: 10
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  # ==========================================
  # ðŸ“– CODE QUALITY STREAM
  # ==========================================

  readability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: setup
    with:
      review-name: readability
      prompt-file: .github/prompts/readability.prompt.md
      timeout-minutes: 8
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  efficiency-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, readability-review]
    with:
      review-name: efficiency
      prompt-file: .github/prompts/efficiency.prompt.md
      timeout-minutes: 10
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  performance-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, efficiency-review]
    with:
      review-name: performance
      prompt-file: .github/prompts/performance.prompt.md
      timeout-minutes: 15
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  # ==========================================
  # ðŸ—ï¸ ARCHITECTURE STREAM
  # ==========================================

  architecture-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: setup
    with:
      review-name: architecture
      prompt-file: .github/prompts/architecture.prompt.md
      timeout-minutes: 20
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  scalability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, architecture-review]
    with:
      review-name: scalability
      prompt-file: .github/prompts/scalability.prompt.md
      timeout-minutes: 15
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  modularity-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, scalability-review]
    with:
      review-name: modularity
      prompt-file: .github/prompts/modularity.prompt.md
      timeout-minutes: 10
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  # ==========================================
  # ðŸ‘¤ USER EXPERIENCE STREAM
  # ==========================================

  usability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: setup
    with:
      review-name: usability
      prompt-file: .github/prompts/usability.prompt.md
      timeout-minutes: 10
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  accessibility-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, usability-review]
    with:
      review-name: accessibility
      prompt-file: .github/prompts/accessibility.prompt.md
      timeout-minutes: 12
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  documentation-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, accessibility-review]
    with:
      review-name: documentation
      prompt-file: .github/prompts/documentation.prompt.md
      timeout-minutes: 8
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  # ==========================================
  # ðŸ”€ CROSS-STREAM CONVERGENCE
  # ==========================================

  reliability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, performance-review, modularity-review]
    with:
      review-name: reliability
      prompt-file: .github/prompts/reliability.prompt.md
      timeout-minutes: 15
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  testability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, modularity-review, safety-review]
    with:
      review-name: testability
      prompt-file: .github/prompts/testability.prompt.md
      timeout-minutes: 12
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  maintainability-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, documentation-review, performance-review, safety-review]
    with:
      review-name: maintainability
      prompt-file: .github/prompts/maintainability.prompt.md
      timeout-minutes: 12
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  compatibility-review:
    uses: ./.github/workflows/opencode-review.yml
    needs: [setup, reliability-review, testability-review]
    with:
      review-name: compatibility
      prompt-file: .github/prompts/compatibility.prompt.md
      timeout-minutes: 12
      use-cache: true
      cache-key: ${{ needs.setup.outputs.opencode-cache-key }}

  # ==========================================
  # ðŸŽ¯ FINAL COMPREHENSIVE SUMMARY
  # ==========================================

  summary:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [
      # Security & Compliance Stream
      security-review, compliance-review, safety-review,
      # Code Quality Stream  
      readability-review, efficiency-review, performance-review,
      # Architecture Stream
      architecture-review, scalability-review, modularity-review,
      # User Experience Stream
      usability-review, accessibility-review, documentation-review,
      # Cross-Stream Convergence
      reliability-review, testability-review, maintainability-review, compatibility-review
    ]
    if: always()
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download All Review Results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-review-results"
          merge-multiple: true

      - name: Create Multi-Stream Report
        run: |
          echo "# ðŸ¤¯ Comprehensive Review Multi-Stream Report" > comprehensive-report.md
          echo "" >> comprehensive-report.md
          echo "Generated on $(date)" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          echo "## ðŸŒŠ Multi-Stream Pipeline Architecture" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          echo "This review uses a **sophisticated multi-stream parallel architecture**:" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          echo "### ðŸ”’ Security & Compliance Stream" >> comprehensive-report.md
          echo "Security â†’ Compliance â†’ Safety" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          echo "### ðŸ“– Code Quality Stream" >> comprehensive-report.md  
          echo "Readability â†’ Efficiency â†’ Performance" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          echo "### ðŸ—ï¸ Architecture Stream" >> comprehensive-report.md
          echo "Architecture â†’ Scalability â†’ Modularity" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          echo "### ðŸ‘¤ User Experience Stream" >> comprehensive-report.md
          echo "Usability â†’ Accessibility â†’ Documentation" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          echo "### ðŸ”€ Cross-Stream Convergence" >> comprehensive-report.md
          echo "Multi-stream dependencies create sophisticated quality gates" >> comprehensive-report.md
          echo "" >> comprehensive-report.md
          
          # Process results by stream
          declare -A streams=(
            ["Security & Compliance"]="security compliance safety"
            ["Code Quality"]="readability efficiency performance"
            ["Architecture"]="architecture scalability modularity"
            ["User Experience"]="usability accessibility documentation"
            ["Cross-Stream"]="reliability testability maintainability compatibility"
          )
          
          for stream in "${!streams[@]}"; do
            echo "## ðŸŒŠ $stream Stream Results" >> comprehensive-report.md
            echo "" >> comprehensive-report.md
            
            for review in ${streams[$stream]}; do
              echo "### ðŸ” ${review^} Review" >> comprehensive-report.md
              if [ -f "${review}-review-results.txt" ]; then
                echo "\`\`\`" >> comprehensive-report.md
                head -n 50 "${review}-review-results.txt" >> comprehensive-report.md
                echo "\`\`\`" >> comprehensive-report.md
              else
                echo "âŒ ${review^} review failed or did not produce results." >> comprehensive-report.md
              fi
              echo "" >> comprehensive-report.md
            done
          done
          
          echo "---" >> comprehensive-report.md
          echo "*ðŸš€ Generated by the Comprehensive Multi-Stream Review System*" >> comprehensive-report.md

      - name: Upload Multi-Stream Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: comprehensive-multi-stream-report
          path: comprehensive-report.md

      - name: Generate Stream Statistics
        run: |
          echo "ðŸ“Š Multi-Stream Review Statistics:" > stream-stats.txt
          echo "=================================" >> stream-stats.txt
          echo "ðŸŒŠ 4 Parallel Streams + Cross-Stream Convergence" >> stream-stats.txt
          echo "" >> stream-stats.txt
          
          declare -A streams=(
            ["ðŸ”’ Security & Compliance"]="security compliance safety"
            ["ðŸ“– Code Quality"]="readability efficiency performance"  
            ["ðŸ—ï¸ Architecture"]="architecture scalability modularity"
            ["ðŸ‘¤ User Experience"]="usability accessibility documentation"
            ["ðŸ”€ Cross-Stream"]="reliability testability maintainability compatibility"
          )
          
          total_success=0
          total_reviews=16
          
          for stream in "${!streams[@]}"; do
            echo "$stream Stream:" >> stream-stats.txt
            stream_success=0
            stream_total=0
            
            for review in ${streams[$stream]}; do
              stream_total=$((stream_total + 1))
              if [ -f "${review}-review-results.txt" ]; then
                stream_success=$((stream_success + 1))
                total_success=$((total_success + 1))
                echo "  âœ… ${review^}: SUCCESS" >> stream-stats.txt
              else
                echo "  âŒ ${review^}: FAILED" >> stream-stats.txt
              fi
            done
            echo "  Stream Success: ${stream_success}/${stream_total}" >> stream-stats.txt
            echo "" >> stream-stats.txt
          done
          
          echo "ðŸŽ¯ OVERALL MULTI-STREAM PIPELINE" >> stream-stats.txt
          echo "===============================" >> stream-stats.txt
          echo "Total Success Rate: ${total_success}/${total_reviews} ($(echo "scale=1; $total_success * 100 / $total_reviews" | bc -l)%)" >> stream-stats.txt
          echo "" >> stream-stats.txt
          echo "ðŸŒŠ Multi-stream parallel execution with cross-dependencies!" >> stream-stats.txt
          
          cat stream-stats.txt

      - name: Upload Stream Statistics
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: multi-stream-statistics
          path: stream-stats.txt